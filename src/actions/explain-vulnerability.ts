'use server';

import { ai } from '@/ai/genkit';
import {
  ExplainVulnerabilityRiskInputSchema,
  ExplainVulnerabilityRiskOutputSchema,
  type ExplainVulnerabilityRiskInput,
  type ExplainVulnerabilityRiskOutput,
} from '@/ai/types';
import type { Host } from '@/types/nmap';
import { getLocale } from 'next-intl/server';
import { z } from 'genkit';

// Flow logic is now defined directly in the server action file

const prompt = ai.definePrompt({
  name: 'explainVulnerabilityRiskPrompt',
  input: {schema: ExplainVulnerabilityRiskInputSchema},
  output: {schema: ExplainVulnerabilityRiskOutputSchema},
  prompt: `You are an expert in cybersecurity vulnerability analysis. Your task is to explain why a given host has been assigned a specific risk score.

  Respond in this language: {{{locale}}}.

  Host Details: {{{hostDetails}}}
  Ranking Factors: {{{rankingFactors}}}
  Risk Score: {{{riskScore}}} / 100

  Analyze all the provided data and generate a clear, concise explanation. Your tone should reflect the risk score.

  - If the risk score is high (>= 75), write a direct and cautionary explanation. Clearly state that the host is vulnerable and detail the critical factors that contribute to this high-risk assessment. Use strong and direct language.
  - If the risk score is medium (40-74), explain that the host has several security weaknesses that should be addressed. Detail the factors and explain the potential risks they pose.
  - If the risk score is low (< 40), state that the host is considered to have a low risk profile. Explain why the risk is low (e.g., few open ports, no critical services exposed). Mention the identified ranking factors as potential areas for improvement or hardening, but do not describe the host as "vulnerable". Use a more informative and less alarming tone.
  
  Provide the explanation and also translate the original ranking factors into the requested locale.
  `,
});

const explainVulnerabilityRiskFlow = ai.defineFlow(
  {
    name: 'explainVulnerabilityRiskFlow',
    inputSchema: ExplainVulnerabilityRiskInputSchema,
    outputSchema: ExplainVulnerabilityRiskOutputSchema,
  },
  async input => {
    const {output} = await prompt(input);
    return output!;
  }
);

// The server action function
export async function getVulnerabilityExplanation(
  host: Host,
  rankingFactors: string
): Promise<ExplainVulnerabilityRiskOutput> {
  try {
    const locale = await getLocale();
    const hostDetails = JSON.stringify(
      {
        ip: host.address.addr,
        status: host.status.state,
        ports: host.ports,
        hostscript: host.hostscript,
      },
      null,
      2
    );

    const result = await explainVulnerabilityRiskFlow({
      hostDetails,
      rankingFactors,
      riskScore: host.riskScore ?? 0,
      locale,
    });

    return result;
  } catch (error) {
    console.error('Error getting vulnerability explanation:', error);
    throw new Error('Failed to generate vulnerability explanation from AI model.');
  }
}
